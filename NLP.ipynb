{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "NLP.ipynb",
      "authorship_tag": "ABX9TyNPXPcGcajrHN+BRcUaL634",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranaya14/DSA0301/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_OnlDxLmp5z",
        "outputId": "d4f0273e-f525-4b3e-db8a-2efd357c703c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download(\"punkt\")\n",
        "stemmer = PorterStemmer()\n",
        "sentences = [ \"I am running in the park\",\n",
        "             \"the running shoes are on sales\",\n",
        "              \"she ran to catch the busses\"]\n",
        "for sentence in sentences:\n",
        "  words = nltk.word_tokenize(sentence)\n",
        "  stemmed_words = [stemmer.stem(word) for word in words ]\n",
        "  stemmed_sentence = \" \".join(stemmed_words)\n",
        "  print(f\"original: {sentence}\")\n",
        "  print(f\"stemmed: {stemmed_sentence}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSqryS1jpjvD",
        "outputId": "752c1ca0-0760-4c07-e7d4-031592a36dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original: I am running in the park\n",
            "stemmed: i am run in the park\n",
            "\n",
            "original: the running shoes are on sales\n",
            "stemmed: the run shoe are on sale\n",
            "\n",
            "original: she ran to catch the busses\n",
            "stemmed: she ran to catch the buss\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "text = \"This is one simple example.\"\n",
        "tokens = word_tokenize(text)\n",
        "tags = nltk.pos_tag(tokens, tagset = \"universal\")\n"
      ],
      "metadata": {
        "id": "IPJB3Y9hxpnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "txt = \"Sukanya, Rajib and Naba are my good friends. \" \\\n",
        "\t\"Sukanya is getting married next year. \" \\\n",
        "\t\"Marriage is a big step in one’s life.\" \\\n",
        "\t\"It is both exciting and frightening. \" \\\n",
        "\t\"But friendship is a sacred bond between people.\" \\\n",
        "\t\"It is a special kind of love between us. \" \\\n",
        "\t\"Many of you must have tried searching for a friend \"\\\n",
        "\t\"but never found the right one.\"\n",
        "\n",
        "# sent_tokenize is one of instances of\n",
        "# PunktSentenceTokenizer from the nltk.tokenize.punkt module\n",
        "\n",
        "tokenized = sent_tokenize(txt)\n",
        "for i in tokenized:\n",
        "\n",
        "\t# Word tokenizers is used to find the words\n",
        "\t# and punctuation in a string\n",
        "\twordsList = nltk.word_tokenize(i)\n",
        "\n",
        "\t# removing stop words from wordList\n",
        "\twordsList = [w for w in wordsList if not w in stop_words]\n",
        "\n",
        "\t# Using a Tagger. Which is part-of-speech\n",
        "\t# tagger or POS-tagger.\n",
        "\ttagged = nltk.pos_tag(wordsList)\n",
        "\n",
        "\tprint(tagged)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_9l6xxVzpYF",
        "outputId": "2ba1db00-174e-48bc-d9eb-b6ee22825d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Sukanya', 'NNP'), (',', ','), ('Rajib', 'NNP'), ('Naba', 'NNP'), ('good', 'JJ'), ('friends', 'NNS'), ('.', '.')]\n",
            "[('Sukanya', 'NNP'), ('getting', 'VBG'), ('married', 'VBN'), ('next', 'JJ'), ('year', 'NN'), ('.', '.')]\n",
            "[('Marriage', 'NN'), ('big', 'JJ'), ('step', 'NN'), ('one', 'CD'), ('’', 'NN'), ('life.It', 'NN'), ('exciting', 'VBG'), ('frightening', 'NN'), ('.', '.')]\n",
            "[('But', 'CC'), ('friendship', 'NN'), ('sacred', 'VBD'), ('bond', 'NN'), ('people.It', 'NN'), ('special', 'JJ'), ('kind', 'NN'), ('love', 'VB'), ('us', 'PRP'), ('.', '.')]\n",
            "[('Many', 'JJ'), ('must', 'MD'), ('tried', 'VB'), ('searching', 'VBG'), ('friend', 'NN'), ('never', 'RB'), ('found', 'VBD'), ('right', 'JJ'), ('one', 'CD'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading : Package '' not found in index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define sentence patterns\n",
        "sentence_patterns = [\n",
        "    \"The {noun} {verb} {adjective}.\",\n",
        "    \"{Noun} {verb} {adjective} {noun}.\",\n",
        "    \"I {verb} {adjective} {noun}.\",\n",
        "    \"She {verb} {noun}.\",\n",
        "    \"He {verb} {adjective} {noun} {adverb}.\",\n",
        "]\n",
        "\n",
        "# Define vocabulary\n",
        "nouns = [\"cat\", \"dog\", \"ball\", \"house\", \"book\"]\n",
        "verbs = [\"runs\", \"jumps\", \"sleeps\", \"reads\", \"eats\"]\n",
        "adjectives = [\"quick\", \"lazy\", \"smart\", \"tall\", \"small\"]\n",
        "adverbs = [\"slowly\", \"quickly\", \"loudly\", \"silently\"]\n",
        "Noun = \"John\"\n",
        "\n",
        "# Function to construct a random sentence\n",
        "def construct_sentence():\n",
        "    pattern = random.choice(sentence_patterns)\n",
        "    sentence = pattern.format(\n",
        "        noun=random.choice(nouns),\n",
        "        verb=random.choice(verbs),\n",
        "        adjective=random.choice(adjectives),\n",
        "        adverb=random.choice(adverbs),\n",
        "        Noun=Noun,\n",
        "    )\n",
        "    return sentence\n",
        "\n",
        "# Generate and print random sentences\n",
        "for _ in range(5):\n",
        "    sentence = construct_sentence()\n",
        "    print(sentence)\n"
      ],
      "metadata": {
        "id": "SxGQ_PFLq_VY",
        "outputId": "97e97553-0a04-4590-cde3-c220d32c1bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He reads quick house loudly.\n",
            "John sleeps quick book.\n",
            "She jumps house.\n",
            "I jumps tall house.\n",
            "The house reads quick.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "txt = \"your shirt collection in fantastic. \"\\\n",
        "      \" is everything okay .\" \\\n",
        "      \"are you fine .\"\n",
        "\n",
        "tokenized = sent_tokenize(txt)\n",
        "for i in tokenized:\n",
        "\twordsList = nltk.word_tokenize(i)\n",
        "\twordsList = [w for w in wordsList if not w in stop_words]\n",
        "\ttagged = nltk.pos_tag(wordsList)\n",
        "\tprint(tagged)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJtft7Mw2fTf",
        "outputId": "b8ef195d-786b-4930-9745-c0589d559046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('shirt', 'NN'), ('collection', 'NN'), ('fantastic', 'NN'), ('.', '.')]\n",
            "[('everything', 'NN'), ('okay', 'PRP'), ('.are', 'JJ'), ('fine', 'JJ'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "brown.words()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMAIcGOG0s7V",
        "outputId": "cac1d30d-c0d5-403f-c0cb-77fb3e8a4df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}